{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('/media/r2-d2/E0C494CDC494A6F6/doutorado/rec_info/data/estupro_teste.csv', sep = ';', encoding = 'utf-8')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HISTORICO</th>\n",
       "      <th>CONTEXTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparece neste plantão os Policiais Milit...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comparece a declarante informando que viveu co...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presente o declarante, informando qu...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comparece nesta especializada a senhora Tatian...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Comparecem nesta delegacia os policiais milita...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2394</th>\n",
       "      <td>Comparece neste plantão os policiais militare...</td>\n",
       "      <td>UNICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2395</th>\n",
       "      <td>Presente a declarante informando que, na tarde...</td>\n",
       "      <td>UNICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2396</th>\n",
       "      <td>Comparecem os GCMs Luciane e Detz apresentando...</td>\n",
       "      <td>UNICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>Comparece nesta Unidade Policial o policial mi...</td>\n",
       "      <td>UNICO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2398</th>\n",
       "      <td>Presente a declarante informando que, na data ...</td>\n",
       "      <td>UNICO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2399 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              HISTORICO   CONTEXTO\n",
       "0         Comparece neste plantão os Policiais Milit...  COTIDIANO\n",
       "1     Comparece a declarante informando que viveu co...  COTIDIANO\n",
       "2               Presente o declarante, informando qu...  COTIDIANO\n",
       "3     Comparece nesta especializada a senhora Tatian...  COTIDIANO\n",
       "4     Comparecem nesta delegacia os policiais milita...  COTIDIANO\n",
       "...                                                 ...        ...\n",
       "2394   Comparece neste plantão os policiais militare...      UNICO\n",
       "2395  Presente a declarante informando que, na tarde...      UNICO\n",
       "2396  Comparecem os GCMs Luciane e Detz apresentando...      UNICO\n",
       "2397  Comparece nesta Unidade Policial o policial mi...      UNICO\n",
       "2398  Presente a declarante informando que, na data ...      UNICO\n",
       "\n",
       "[2399 rows x 2 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/r2-d2/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# baixando as libs para pre processamento\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import re\n",
    "from unidecode import unidecode\n",
    "\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stopwords = set(stopwords.words('portuguese'))\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "#nltk.download(\"wordnet\")\n",
    "#from nltk.stem import WordNetLemmatizer\n",
    "#lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pre processamento\n",
    "\n",
    "    # Remover caracteres especiais e números\n",
    "    #text = re.sub('[^A-Za-z\\s\\']+', '', text)\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    padrao_arroba = re.compile(r'@\\S+')\n",
    "      # Remover as strings com \"@\" no início da string\n",
    "    text = re.sub(padrao_arroba, '', text)\n",
    "\n",
    "        #remover sites\n",
    "    #pattern_url = re.compile(r'https?:\\/\\/.*?[\\s+]')\n",
    "\n",
    "    text = re.sub(r'http\\S+', '', text)\n",
    "    \n",
    "\n",
    "    # Converter tudo para letras minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    \n",
    "    # Remover as tags HTML\n",
    "    text = re.sub('<[^<]+?>', '', text)    \n",
    "\n",
    "    text = unidecode(text)\n",
    "    \n",
    "    \n",
    "    # Tokenizar o texto em palavras\n",
    "    words = nltk.word_tokenize(text)\n",
    "\n",
    "    # remover palavras que so possua caractere especial\n",
    "    words = [word for word in words if not re.match('^[^A-Za-z0-9]+$', word)]\n",
    "\n",
    "    # remover palavras que tenha tamanho 1\n",
    "    words = [word for word in words if len(word) > 2]\n",
    "\n",
    "    \n",
    "    # Remover as stopwords\n",
    "    words = [word for word in words if word not in stopwords]\n",
    "    \n",
    "    # Aplicar o stemming\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    #words = [lemmatizer.lemmatize(word) for word in words]\n",
    "\n",
    "    # Juntar as palavras em uma única string\n",
    "    text = ' '.join(words)\n",
    "  \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rodar o pre processamento\n",
    "\n",
    "def preprocess_collection(docs):\n",
    "\n",
    "    preprocessed_documents = []\n",
    "\n",
    "    #for document in docs:\n",
    "    for index, row in docs.iterrows():\n",
    "        tema = row['CONTEXTO']\n",
    "        #nome_arquivo = document['nome_arquivo']\n",
    "        conteudo = row['HISTORICO']\n",
    "        \n",
    "        preprocessed_conteudo = preprocess_text(conteudo)\n",
    "        \n",
    "        preprocessed_document = {\n",
    "            'tema': tema,\n",
    "        #    'nome_arquivo': nome_arquivo,\n",
    "            'conteudo': preprocessed_conteudo\n",
    "        }\n",
    "        \n",
    "        preprocessed_documents.append(preprocessed_document)\n",
    "        \n",
    "    return preprocessed_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HISTORICO</th>\n",
       "      <th>CONTEXTO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Comparece neste plantão os Policiais Milit...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Comparece a declarante informando que viveu co...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Presente o declarante, informando qu...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Comparece nesta especializada a senhora Tatian...</td>\n",
       "      <td>COTIDIANO</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           HISTORICO   CONTEXTO\n",
       "0      Comparece neste plantão os Policiais Milit...  COTIDIANO\n",
       "1  Comparece a declarante informando que viveu co...  COTIDIANO\n",
       "2            Presente o declarante, informando qu...  COTIDIANO\n",
       "3  Comparece nesta especializada a senhora Tatian...  COTIDIANO"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('CONTEXTO')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed_documents = preprocess_collection(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(preprocessed_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "frases = [o['conteudo'] for o in preprocessed_documents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vetorizando\n",
    "\n",
    "#temas = [doc[\"tema\"] for doc in preprocessed_documents]\n",
    "temas = []\n",
    "for doc in preprocessed_documents:\n",
    "    temas.append(doc['tema'])\n",
    "\n",
    "\n",
    "conteudos = [doc[\"conteudo\"] for doc in preprocessed_documents]\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "tfidf_matrix = vectorizer.fit_transform(conteudos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tema': 'COTIDIANO',\n",
       " 'conteudo': 'comparecem nesta delegacia policia conselheira tutelar claudia ligia noticiando caso suposto abuso crianca estupro vulneravel fazendo vitima crianca qualificada sete ano idad conselheira informam tomaram conhecimento crianca acima sido supostament abusada sexualment padrasto cicero pereira santo testemunha acima arrolada relataram conhecem vizinho sandra campo elia cicero pereira santo bem filha sandra crianca raissa elia rubio alvejaniea sete ano idad esclarecendo raissa amiguinha filha ana leticia ano idad frequencia brincam junta sexta-feira dia 16/04/21 crianca raissa ate casa brincar ana leticia ond deve ter chegado volta 18h30 afirmaram certo momento durant jantar avisaram raissa iriam leva-la embora momento ana leticia afirm raissa nao queria embora porqu padrasto dede cicero fazia mal assim conversa sobr assunto crianca acab relatando dede passava mao regiao vagin relatando fato tambem meio gesto testemunha disseram crianca relat fato maneira sincera coerent afirmando padrasto ant leva-la baba passava mao genitalia sentia dor perguntada sobr dede fazia diss nao havendo relato retirava roupa mandava passar mao nele havia ocorrido penetracao perguntaram crianca havia contado fato mae diss sim continuava namorar dede perguntada havia relatado pai diss nao soubess pai dede morreriam contaram pouco tard sandra mae crianca local busca-la sendo fato relatado diss absurdo afirmando menina veze inventava estoria porem tudo revelado sandra afirm iria manter crianca afastada cicero porem acab indo embora crianca volta 22h sendo orientada preservar integridad crianca relato disseram sabado 17/04 acionaram conselho tutelar deu volta 11h tendo relatado fato disso souberam conselheira resolveram procurar sandra encaminharam crianca atendimento medico junto hospit desta cidad ond medico dr. antonio carlo bossolani toledo resolveu encaminhar crianca hospit municip bebedouro atendida diretament ginecologista assim crianca mae bebedouro veiculo disponibilizado prefeitura contudo crianca nao atendida porqu soub conselheira nao present conselheira apresentaram copia ficha medica vitima bem boletim atendimento sobr fato comprometendo apresentar oportunament relatorio detalhado depoimento testemunha reduzido termo sera oficiada secretaria saud municipio disponibil atendimento psicologico vitima promova escuta especializada'}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocessed_documents[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "    input_tfidf = vectorizer.transform([preprocessed_documents[10]['conteudo']])\n",
    "    similaridades = cosine_similarity(input_tfidf, tfidf_matrix)[0]\n",
    "\n",
    "    resultados = list(zip(similaridades, temas, conteudos))\n",
    "    resultados.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(temas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1500"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(conteudos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset de teste\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('data/Corona_NLP_test.csv', encoding = \"ISO-8859-1\")\n",
    "df_test_new = df_test[['OriginalTweet', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OriginalTweet</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRENDING: New Yorkers encounter empty supermar...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When I couldn't find hand sanitizer at Fred Me...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Find out how you can protect yourself and love...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#Panic buying hits #NewYork City as anxious sh...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#toiletpaper #dunnypaper #coronavirus #coronav...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3793</th>\n",
       "      <td>Meanwhile In A Supermarket in Israel -- People...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3794</th>\n",
       "      <td>Did you panic buy a lot of non-perishable item...</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3795</th>\n",
       "      <td>Asst Prof of Economics @cconces was on @NBCPhi...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3796</th>\n",
       "      <td>Gov need to do somethings instead of biar je r...</td>\n",
       "      <td>Extremely Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3797</th>\n",
       "      <td>I and @ForestandPaper members are committed to...</td>\n",
       "      <td>Extremely Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3798 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          OriginalTweet           Sentiment\n",
       "0     TRENDING: New Yorkers encounter empty supermar...  Extremely Negative\n",
       "1     When I couldn't find hand sanitizer at Fred Me...            Positive\n",
       "2     Find out how you can protect yourself and love...  Extremely Positive\n",
       "3     #Panic buying hits #NewYork City as anxious sh...            Negative\n",
       "4     #toiletpaper #dunnypaper #coronavirus #coronav...             Neutral\n",
       "...                                                 ...                 ...\n",
       "3793  Meanwhile In A Supermarket in Israel -- People...            Positive\n",
       "3794  Did you panic buy a lot of non-perishable item...            Negative\n",
       "3795  Asst Prof of Economics @cconces was on @NBCPhi...             Neutral\n",
       "3796  Gov need to do somethings instead of biar je r...  Extremely Negative\n",
       "3797  I and @ForestandPaper members are committed to...  Extremely Positive\n",
       "\n",
       "[3798 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test_sorted = df_test_new.sort_values('Sentiment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_consultas_preproc = preprocess_collection(df_test_sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tema': 'Extremely Positive',\n",
       " 'conteudo': 'grocery store worker also front lines- thankful need protect coronavirus protecting employee serving absolutely necessary role society'}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_consultas_preproc[600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'COTIDIANO': {'p10': 0, 'p20': 0, 'p50': 0, 'p100': 0, 'map': 0}, 'EVENTUAL': {'p10': 0, 'p20': 0, 'p50': 0, 'p100': 0, 'map': 0}, 'UNICO': {'p10': 0, 'p20': 0, 'p50': 0, 'p100': 0, 'map': 0}}\n"
     ]
    }
   ],
   "source": [
    "array_temas = ['COTIDIANO',\n",
    "'EVENTUAL',\n",
    "'UNICO']\n",
    "result_final = {}\n",
    "\n",
    "for d in array_temas:\n",
    "    result_final[d] = {'p10': 0, 'p20': 0, 'p50': 0, 'p100': 0, 'map': 0}\n",
    "\n",
    "print(result_final)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcula_map(resultados, tema_verificado):\n",
    "    acertos = 0\n",
    "    maps = []\n",
    "    #for i, doc in enumerate(ranking):\n",
    "    for i, (similaridade, tema, conteudo) in enumerate(resultados, start=1):\n",
    "        if tema_verificado == tema:\n",
    "            acertos +=1\n",
    "            maps.append(acertos/(i+1))\n",
    "    return mean(maps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trocou\n",
      "trocou\n",
      "trocou\n"
     ]
    }
   ],
   "source": [
    "from statistics import mean\n",
    "\n",
    "#input_documento = doc_consultas_preproc[150]['conteudo']\n",
    "\n",
    "p10 = []\n",
    "p20 = []\n",
    "p50 = []\n",
    "p100 = []\n",
    "map_f = []\n",
    "tema_atual = \"\"\n",
    "for c, input_documento in enumerate(preprocessed_documents):\n",
    "    #print(c)\n",
    "    if c == 0:\n",
    "        tema_atual = input_documento['tema']\n",
    "    #print(tema_atual)\n",
    "    acertos = 0     \n",
    "\n",
    "    input_tfidf = vectorizer.transform([input_documento['conteudo']])\n",
    "    similaridades = cosine_similarity(input_tfidf, tfidf_matrix)[0]\n",
    "\n",
    "    resultados = list(zip(similaridades, temas, conteudos))\n",
    "    resultados.sort(reverse=True)\n",
    "    #print(len(resultados))\n",
    "    map_f.append(calcula_map(resultados, input_documento['tema']))\n",
    "    for rank, (similaridade, tema, conteudo) in enumerate(resultados, start=1):\n",
    "        #print(rank)\n",
    "        if input_documento['tema'] == tema:\n",
    "            #print(\"acertou\")\n",
    "            acertos += 1\n",
    "            \n",
    "        if rank == 10:\n",
    "            #print(\"deu 10\")\n",
    "            p10.append(acertos/10.0)\n",
    "            #print(p10)\n",
    "        if rank == 20:\n",
    "            p20.append(acertos/20.0)\n",
    "        if rank == 50:\n",
    "            p50.append(acertos/50.0)\n",
    "        if rank == 100:\n",
    "            p100.append(acertos/100.0)\n",
    "        \n",
    "    \n",
    "    if tema_atual != input_documento['tema'] or c == len(preprocessed_documents) - 1:\n",
    "        print(\"trocou\")\n",
    "#        print(p10)\n",
    "        result_final[tema_atual]['p10'] = mean(p10)\n",
    "        result_final[tema_atual]['p20'] = mean(p20)\n",
    "        result_final[tema_atual]['p50'] = mean(p50)\n",
    "        result_final[tema_atual]['p100'] = mean(p100)     \n",
    "        result_final[tema_atual]['map'] = mean(map_f)\n",
    "        p10 = []\n",
    "        p20 = []\n",
    "        p50 = []\n",
    "        p100 = []\n",
    "        map_f = []           \n",
    "\n",
    "    tema_atual = input_documento['tema']        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'COTIDIANO': {'p10': 0.550936329588015,\n",
       "  'p20': 0.5270287141073658,\n",
       "  'p50': 0.5040948813982522,\n",
       "  'p100': 0.4893882646691636,\n",
       "  'map': 0.4027031716837907},\n",
       " 'EVENTUAL': {'p10': 0.46332916145181474,\n",
       "  'p20': 0.4326032540675845,\n",
       "  'p50': 0.4065081351689612,\n",
       "  'p100': 0.39296620775969965,\n",
       "  'map': 0.35909269850215414},\n",
       " 'UNICO': {'p10': 0.5387984981226533,\n",
       "  'p20': 0.5143929912390488,\n",
       "  'p50': 0.48630788485607007,\n",
       "  'p100': 0.46759699624530665,\n",
       "  'map': 0.41316800737152065}}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/media/r2-d2/E0C494CDC494A6F6/doutorado/rec_info/results/est/est_tfidf_menor.json', 'w') as f:\n",
    "    json.dump(result_final, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(result_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "df =df.transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p10</th>\n",
       "      <th>p20</th>\n",
       "      <th>p50</th>\n",
       "      <th>p100</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>COTIDIANO</th>\n",
       "      <td>0.550936</td>\n",
       "      <td>0.527029</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.489388</td>\n",
       "      <td>0.402703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>EVENTUAL</th>\n",
       "      <td>0.463329</td>\n",
       "      <td>0.432603</td>\n",
       "      <td>0.406508</td>\n",
       "      <td>0.392966</td>\n",
       "      <td>0.359093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UNICO</th>\n",
       "      <td>0.538798</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.486308</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.413168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                p10       p20       p50      p100       map\n",
       "COTIDIANO  0.550936  0.527029  0.504095  0.489388  0.402703\n",
       "EVENTUAL   0.463329  0.432603  0.406508  0.392966  0.359093\n",
       "UNICO      0.538798  0.514393  0.486308  0.467597  0.413168"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p10</th>\n",
       "      <th>p20</th>\n",
       "      <th>p50</th>\n",
       "      <th>p100</th>\n",
       "      <th>map</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.517688</td>\n",
       "      <td>0.491342</td>\n",
       "      <td>0.465637</td>\n",
       "      <td>0.449984</td>\n",
       "      <td>0.391655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.047466</td>\n",
       "      <td>0.051260</td>\n",
       "      <td>0.051974</td>\n",
       "      <td>0.050567</td>\n",
       "      <td>0.028681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.463329</td>\n",
       "      <td>0.432603</td>\n",
       "      <td>0.406508</td>\n",
       "      <td>0.392966</td>\n",
       "      <td>0.359093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.501064</td>\n",
       "      <td>0.473498</td>\n",
       "      <td>0.446408</td>\n",
       "      <td>0.430282</td>\n",
       "      <td>0.380898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.538798</td>\n",
       "      <td>0.514393</td>\n",
       "      <td>0.486308</td>\n",
       "      <td>0.467597</td>\n",
       "      <td>0.402703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.544867</td>\n",
       "      <td>0.520711</td>\n",
       "      <td>0.495201</td>\n",
       "      <td>0.478493</td>\n",
       "      <td>0.407936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.550936</td>\n",
       "      <td>0.527029</td>\n",
       "      <td>0.504095</td>\n",
       "      <td>0.489388</td>\n",
       "      <td>0.413168</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p10       p20       p50      p100       map\n",
       "count  3.000000  3.000000  3.000000  3.000000  3.000000\n",
       "mean   0.517688  0.491342  0.465637  0.449984  0.391655\n",
       "std    0.047466  0.051260  0.051974  0.050567  0.028681\n",
       "min    0.463329  0.432603  0.406508  0.392966  0.359093\n",
       "25%    0.501064  0.473498  0.446408  0.430282  0.380898\n",
       "50%    0.538798  0.514393  0.486308  0.467597  0.402703\n",
       "75%    0.544867  0.520711  0.495201  0.478493  0.407936\n",
       "max    0.550936  0.527029  0.504095  0.489388  0.413168"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
